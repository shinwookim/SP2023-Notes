# Data Representation
## Binary Encoding
### Positional Numbers (_bits, bites, nybbles_)
The numbers we use are usually written positionlly. The position of a digit within the number has a meaning.
$$2022=2000+000+20+2=2\times{10^3}+0\times{10^2}+2\times{10^1}+2\times{10^0}$$
The left most digit is called "**most significant**", the right most is called "**least significant**".

In our "_decimal_" system, we have 10 digits(symbols): `0, 1, 2, 3, 4, 5, 6, 7, 8, 9 `. 
Using base **10**, a number represented by the digits: $d_{n-1}...d_1d_0$ has the value $d{n-1}\times10^{n-1}+...+d_1\times10^1+d_0\times10^0$. 
Using $n$ digits we can represent $10^n$ different numbers.
+ The smallest non-negative number representable with $n$ digits is $0$. 
+ The largest number representable with $n$ digits is $10^n-1$. 
### Binary - Base 2
In the _binary system_, we have 2 symbols: `0, 1`.
Using base **2**, a number represented by the digits: $d_{n-1}…d_1 d_0$ has the value $d_{n-1}×2 ^{n-1}+…+d_1×2^1+d_0×2^0$.
Using n digits we can represent $2^n$ different numbers.
+ The smallest non-negative number representable with $n$ digits is $0$.
+ The largest number representable with n digits is $2^n-1$.

We call a **B**inary dig**IT** a **bit**, which is a single `1` or `0`. When we say $n$-bit number, we mean one with $n$ binary digits.

#### Convert Between Binary and Decimal
To convery binary to decimal, we ignore the `0`s, add up the place values wheenver there is a `1`.
`1001 0110` = $1\times 2^7+0 \times 2^6+0\times 2^5+1\times 2^5+0\times 2^3+1\times 2^2+1\times 2^1+\times 2^0=128+16+4+2=150_{10}$

 To convert decimal to binary, we can continue to divide by `2` until we reach a quotient `0`. If we read the remainders in the reverse order, we have our binary representation.
 ![[BintoDec.png|150]]
 + A ***bit*** is one binary digit, and its unit is **lowercase** `b`.
 + A ***byte*** is an 8-bit value, and its unit is **UPPERCASE** `B`.
 + A ***nibble*** (also nybble) is 4 bits - half a byte; Corresponds to a single hex digit.
 + A ***word*** is the "*most comfortable size*" of number for a CPU.
	 + In a 32-bit CPU, we mean that its ***word*** size is 32 bits. This means it can, for example, add two 32-bit numbers at once.
	 + Some things (Windows, x86) use **word** to mean 16 bits and **double word** (or **dword**) to mean **32 bits**.
Everything in a computer is a number, represented in binary. Java strings are encoded using **UTF-16**. Most letters and numbers in the English alphabet are < 128, and strings are just a series of numbers. ASCII is also pretty common (and we will use ASCII to represent characters). Letters and numbers (and most ascii characters) have the same value as UTF-16.

### Hexadecimal - Base 16
Using binary has shortcomings:
1. Binary numbers can get really long, really quickly.
E.g., ${3,927,664}_{10} = {11 1011 1110 1110 0111 0000}_2$
2. Nice "round" numbers in binary look arbitrary in decimal (because 10 is not a power of 2).
E.g., $1000000000000000_2 = 32,768_{10}$

An alternative is to use a different base (4, 8, 16, 32...).
Base-4 is not much concise than binary, and base-32 requires 32+ symbols which isn't that intuitive (_for humans_).

Base-8 and base-16 look promising, but we'll stick with base 16

In the Hexadecimal system, we have 16 symbols: `0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F`
Using base **16**, a number represented by the digits: $d{n-1}...d_1d_0$ has the value $d_{n-1} \times 16^{n-1}+…+d_1 \times 16^1 + d_0\times 16^0$.
Using $n$ digits we can represent $16^n$ different numbers, where:
+ The smallest non-negative number representable with $n$ digits is $0$
+ The largest number representable with $n$ digits is $16^n-1$.
We usually call one hexadecimal digit a *hex digit*.

E.g., `003B EE70` $$=0 \times 16^{7}+0 \times 16^{6}+3 \times 16^{5}+11 \times 16^{4}+14 \times 16^{3}+14 \times 16^2+7\times16^1+0\times16^0=3927664_{10}$$
#### Convert Between Decimal and Hexadecimal
But we can convert from decimal to hexadecimal in a simpler way by using the same method for converting decimal to binary. We can continue to divide by `16` until we reach a quotient that is less than the divisor. If we read the remainders in the reverse order, we have our binary representation.
![[Pasted image 20221023204922.png]]
#### Convert Between Binary and Hexadecimal
To convert from Binary to Hexadecimal, we can simply group the binary numbers into 4s, and then convert them each to hexadecimal (Append 0s to the front if needed). 
E.g,
| 0010 | 0100 | 0110 | 1111 | 1000 | 0110 | 1001 | 0101 |
|------|------|------|------|------|------|------|------|
| 2 | 4 | 6 | F | 8 | 6 | 9 | 5 |
$\therefore$ `10 0100 0110 1111 1000 0110 1001 0101` = `0x246F8695`
This method works because 4 bits = 1 hexadecimal digit.

E.g,
$$
\verb|1111 1111|_2
= 1 \times 2^7 + 1 \times 2^6 + 1 \times 2^5 +1 \times 2^4 +1 \times 2^3 +1 \times 2^2 +1 \times 2^1 +1 \times 2^0 
$$
Notice that  $$1 \times 2^3 +1 \times 2^2 +1 \times 2^1 +1 \times 2^0 = 8+4+2+1=15$$
Which means $$\verb|1111 1111|_2
= (1 \times 2^3 +1 \times 2^2 +1 \times 2^1 +1 \times 2^0)\times 2^4 +15=15\times16^1+15\times16^0 = \verb|0xFF| $$
### Powers of Two
|           |     Dec    |      Hex     |
|:---------:|:----------:|:------------:|
|     2<sup>0</sup>    |      1     |      0x1     |
|     2<sup>1</sup>    |      2     |      0x2     |
|     2<sup>2</sup>    |      4     |      0x4     |
|     2<sup>3</sup>    |      8     |      0x8     |
|     2<sup>4</sup>    |      16    |      0x10    |
|     2<sup>5</sup>    |      32    |      0x20    |
|     2<sup>6</sup>    |      64    |      0x40    |
|     2<sup>7</sup>    |     128    |      0x80    |
|     2<sup>8</sup>    |     256    |     0x100    |
+ Notice that the largest number than an 8-bit value can hold is 255 or `0xFF`. Similarly, the largest value that a 16-bit value can hold is 65535 or `0xFFFF`.

## Integer Encoding
### Overflow and the Number Circle
Recall that the numbers on a computer act like a number circle. That means when they go over their maximum value, they overflow.

E.g., Suppose `positive_tiny` can hold at most 4 bits.
```C
	positive_tiny number = 14;
	print << (number + 1); // Prints 15
	print << (number + 2); // Prints 0 - NOT 16
	print << (number + 3); // Prints 1 - NOT 17
	
```
![[Pasted image 20221023210654.png]]
### Negative Numbers
Recall how the computer stores negative numbers. Half of the number circle is dedicated to negative numbers, the other half for positive numbers. Also, overflow can still happen. We detected this in the following two cases:
1. Neg + Neg = Pos $\implies$ Overflow
2. Pos + Pos = Neg $\implies$ Overflow
Recall that we can never get an overflow if the signs are different because it moves us closer to zero.

E.g, Suppose `tiny` can hold 4 bit positive and negative numbers.
```C
tiny number = -7;
print << (number - 1); // Prints -8
print << (number - 2); // Prints 7; NOT -9
```
![[Pasted image 20221023211113.png]]
### Signed Numbers (2's Complement)
Recall that 2's complement representation is lopsided.
![[Pasted image 20221023211354.png]]
+ For 3 bits numbers, -4 does not have a valid positive counterpart. In fact, the negative numbers always have 1 more than the positive.
+ We know a numbers is positive if its MostSignificantBit is 1.
#### Two's Complement Arithmetic
##### Negation
To negate $3$ (to get $-3$):
1. We first write down the bit pattern for $3$: $\verb|0011|_2$ 
2. We then flip the bits: $\verb|1100|_2$
3. Lastly we add `1`: $\verb|1101|_2$ 
To negate $-3$ (to get 3):
1. We first write down the bit patter form $-3: \verb|1101|_2$
2. We then flip the bits: $0010$
3. Lastly we add `1`: $\verb|0011|_2$
##### Addition
Addition for two's complement is simple. We can add numbers of either sign without having to do anything special.

##### Integer Ranges
Recall that the range of an unsigned integer was $0$ to $2^n-1$. Now, we lose a bit due to the sign bit meaning we can represent signed integers between $-2^{n-1}$ to $2^{n-1}-1$.

E.g, Consider the following Java program:
```Java
public class AbsTest {
	public static int abs(int x){
		if (x < 0) {
			x = -x;
		}
		return xl
	}
}
public static void main(String[] args){
	System.out.println(
		String.format("|%d| = %d", Integer.MIN_VALUE, AbsTest.abs(Integer.MIN_VALUE))
	);
}
```
This code outputs `|-2147483648| = -2147483648`. Why? because two's complement is lopsided. The negation of `Integer.MIN_VALUE` does not exist.

## Integers
### Integers in C
C allows for variables to be declared as either signed or unsigned. An unsigned integer varaible has a range from $0$ to $2^n-1$; Signed integers are usually two's complement and have the range $-2^{n-1}$ to $2^{n-1}-1$. (1. $n$ is determined by the variable's size in bits 2. Although 2's complement is not mandated by C, most machines use it).

Integer Types - (Signed by default, sizes are arbitrary)
| Type | Unsigned | Size |
|-------|------------|-----|
| `char` | `unsigned char` | 8 bits (byte)|
|`short int` | `unsigned short int` | 16 bits (half-word)|
|`int` | `unsigned int` | 32 bits (word)|
|`long int`|`unsigned long int`|64 bits (double-word)|

#### Quiz
Given the declaration:
```C
signed int x = ???;
unsigned int ux = ???;
```
Are the following statements True or False?
1. `x < 0` $\implies$ `((x*2) < 0)`
2. `ux >= 0`
3. `ux > -1` 
4. `x > y` $\implies$ `-x < -y`  ____
5. `x * x >= 0`
6. `x > 0 && y > 0` $\implies$ `x + y > 0`
7. `x >= 0`  $\implies$ `-x <= 0`  ____
8. `x <= 0` $\implies$  `-x >= 0`

#### Limits & Sizes
Since sizes of integers are technically arbitrary, they are usually based on the underlying architecture.

`C` provides standard library constants defining the ranges.
```C
#include <limits.h>		  // Provides INT_MAX etc
#include <stdio.h>		  // Provides printf

int main() {
  printf("%d ",  INT_MAX);	  // Print the maximum signed int
  printf("%u\n", UINT_MAX);	  // Print the maximum unsigned int
  return 0;
}		    // Output: 2147483647 4294967295
```

Also `sizeof` gives us the ability to programatically obtain the byte size of data.
```C
sizeof(int); // ->32 on a typical 64-bit system

long long_variable = 0;
sizeof(long_variable); // ->64 on a typical 64-bit system
```

We can get the size of all types using:
```C
#include <stdio.h>   // Gives us 'printf’
int main(void) {
	printf("sizeof(x):    (bytes)\n");
	printf("char:         %lu\n", sizeof(char));
	printf("short:        %lu\n", sizeof(short));
	printf("int:          %lu\n", sizeof(int));
	printf("unsigned int: %lu\n", sizeof(unsigned int));
	printf("long:         %lu\n", sizeof(long));
	printf("float:        %lu\n", sizeof(float));
	printf("double:       %lu\n", sizeof(double));
	return 0;
}

```

### C Data Types Summary
|     Data Type    |     Typical 32-bit size    |     Typical 64-bit size    |     Typical 64-bit unsigned ranges    |     Typical 64-bit signed ranges    |
|------------------|----------------------------|----------------------------|---------------------------------------|-------------------------------------|
|     char         |              1             |              1             |                0 .. 28-1              |             -27 ..   27-1           |
|     short        |              2             |              2             |               0 .. 216-1              |            -215 ..   215-1          |
|     int          |              4             |              4             |               0 .. 232-1              |            -231 ..   231-1          |
|     long         |              4             |              8             |               0 .. 264-1              |            -263 ..   263-1          |
|     float        |              4             |              4             |                  Erm….                |                 Erm….               |
|     double       |              8             |              8             |                  Erm….                |                 Erm….               |
|     “address”    |              4             |              8             |               0 .. 264-1              |                 Erm….               |

### Casting & Coercion
We can convert between signed & unsigned through casting:
```C
int sx, sy;
sx = (int) ux;
uy = (unsigned) sy;
```
C lets us move a value from an unsigned integer variable to a signed integer variable. (and vice versa). However, this is not always valid! Yet, it will do it anyway. The binary value is the same, its interpretation is not! This is called **coercion**, and this is a relatively simple case of it. Since it ignores obvious invalid operations this is sometimes referred to as “weak” typing. The strong/weak terminology has had very fragile definitions over the years and are arguably useless in our context. 
+ Moving values between different types is called **casting**
```C
#include <stdio.h>
#include <limits.h>
int main()
{
	int i = -1;
	unsigned u = i; // same as (unsigned)i;
	printf("i=%d, u=%u\n", i, u);
	return 0;
}
// Output: i=-1, u=4294967295
int main()
{
	int i = 10;
	float f = (float)i;
	printf("i=%d, f=%f\n", i, f);
	return 0;
}
// Output: i=10, f=10.000000
```
We must be careful as implicit casting also occurs via assignments and procedure calls

+ Integer literals (constants)
	+ By default, integer constants are considered signed integers
	+ Hex constants already have an explicit binary representation
	+ Use “U” (or “u”) suffix to explicitly force unsigned
	+ Examples:  `0U`, `4294967259u`
+ Expression Evaluation
	+ When you mixed unsigned and signed in a single expression, signed values are implicitly cast to unsigned
	+ Including comparison operators `<`, `>`, `==`, `<=`, `>=`
![[Pasted image 20221023215050.png]]

